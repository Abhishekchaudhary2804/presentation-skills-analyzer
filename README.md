Presentation & Communication Skills Analyzer

A real-time computer vision system that analyzes presentation skills using webcam or recorded video.
The system evaluates eye contact, posture, hand gestures, and overall confidence, then generates a CSV session log and PDF performance report with improvement tips.

Built using Python + OpenCV + MediaPipe Tasks API.

ğŸš€ Features

âœ… Live webcam or recorded video support
âœ… Eye contact / gaze stability analysis
âœ… Posture & slouch detection
âœ… Hand gesture usage scoring
âœ… Overall confidence score (0â€“100)
âœ… Rule-based improvement tips
âœ… Session CSV export
âœ… Automated PDF report generation

ğŸ§  Skill Metrics

The system computes:

Eye Contact Score

Posture Score

Gesture Score

Confidence Score

Confidence is calculated as:

Confidence = 0.4 Ã— Eye + 0.3 Ã— Posture + 0.3 Ã— Gesture

ğŸ“ Project Structure
presentation_analyzer/
â”‚
â”œâ”€â”€ main.py              # Main application
â”œâ”€â”€ face.py              # Eye contact detection
â”œâ”€â”€ pose.py              # Posture detection
â”œâ”€â”€ hands.py             # Gesture detection
â”œâ”€â”€ scoring.py           # Confidence + tips logic
â”œâ”€â”€ pdf_report.py        # PDF generator
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ face_landmarker.task
â”‚   â”œâ”€â”€ pose_landmarker.task
â”‚   â””â”€â”€ hand_landmarker.task
â”‚
â”œâ”€â”€ session.csv          # Auto-generated after run
â”œâ”€â”€ session_report.pdf  # Final PDF report
â””â”€â”€ README.md

ğŸ›  Tech Stack

Python 3.11

OpenCV

MediaPipe Tasks API

NumPy

Pandas

ReportLab (PDF generation)

âš™ Installation
1. Create virtual environment (Python 3.11)
py -3.11 -m venv venv
venv\Scripts\activate

2. Install dependencies
pip install mediapipe opencv-python numpy pandas matplotlib reportlab

3. Download Models

Create folder:

models/


Download and place inside:

face_landmarker.task

pose_landmarker.task

hand_landmarker.task

(From MediaPipe official model zoo.)

â–¶ Run Application
python main.py


Press Q to stop session.

After exit:

session.csv is created

session_report.pdf is generated automatically

ğŸ“„ Output
CSV:

Frame-wise scores for Eye, Posture, Gesture, Confidence.

PDF:

Final averages + personalized improvement tips.

ğŸ’¡ Example Improvement Tips

Increase eye contact with camera

Straighten posture and reduce slouch

Use more natural hand gestures

ğŸ¯ Use Cases

Presentation practice

Interview preparation

Public speaking improvement

Soft-skills analytics demo

ğŸ† Resume Description

Built a real-time Presentation Skills Analyzer using Python, OpenCV and MediaPipe Tasks API to evaluate eye contact, posture, gestures and confidence, generating automated CSV and PDF performance reports.

ğŸ”® Future Improvements

Audio speaking pace analysis

ML classifier (confident / nervous / distracted)

Web dashboard

Historical session comparison


ğŸ“ˆ Evaluation Notes

Eye contact estimated using iris center approximation.

Posture calculated via shoulder alignment and head forward distance.

Hand gestures measured using wrist movement across frames.

Scores are rule-based and not ML-trained.

Lighting and camera angle affect accuracy.

Designed for single-person frontal presentation.

ğŸ‘¤ Author

Abhishek Chaudhary
AI / Computer Vision Project